{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification 2:\n",
    "* Dataset: http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "* Target: pos/neg folders\n",
    "* Metric: AUC-ROC\n",
    "* Libraries: scikit‑learn + NLTK\n",
    "* Text preprocessing – 3\n",
    "    - Removing stop words\n",
    "    - Stemming / Lemmatization\n",
    "    - Bag of words / TF-IDF\n",
    "    - N-grams\n",
    "* Words importance - 2\n",
    "* Hyperparameters tuning – 1\n",
    "* Compare performance of models: SGDClassifier; SVM; Naive Bayes - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некий план:\n",
    "* придумать как в gs вычислять три метрики сразу\n",
    "* придумать как в gs вместо кросс-валидации использовать тестовую выборку?\n",
    "* заценить оригинальную статью\n",
    "* text preprocessing\n",
    "* feature engineering\n",
    "* words importance?\n",
    "* pipeline with sgd/svm/bayes + gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем README:\n",
    "* по 25к файлов на train/test, по 12.5к файлов на pos/neg\n",
    "* pos – рейтинг >= 7, neg – рейтинг <= 4\n",
    "* в название файлов включен рейтинг\n",
    "* есть отдельный файл со ссылками на imdb, т.е. известно, какому фильму принадлежат рейтинги\n",
    "* но толку от этого предположительно нуль, потому что фильмы в train/test не повторяются\n",
    "* есть авторский bag of words в libsvm формате"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заменим тысячи файлов двумя train.json + test.json, куда включим собственно отзывы, таргет, рейтинг, и идентификатор фильма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample2json(sample):\n",
    "    if sample not in ['train', 'test']:\n",
    "        raise ValueError\n",
    "    \n",
    "    data = []\n",
    "    for target in tqdm_notebook(['pos', 'neg'], desc='target', leave=False):\n",
    "        with open('data/imdb/%s/urls_%s.txt' % (sample, target)) as file:\n",
    "            urls = file.readlines()\n",
    "\n",
    "        for index, filename in tqdm_notebook(enumerate(os.listdir('data/imdb/%s/%s' % (sample, target))), desc='file', leave=False):\n",
    "            file_id, rating = filename.split('_')\n",
    "            rating = rating[:rating.index('.')]\n",
    "            \n",
    "            with open('data/imdb/%s/%s/%s' % (sample, target, filename)) as file:\n",
    "                data.append({\n",
    "                    'file_id': file_id,\n",
    "                    'rating': int(rating),\n",
    "                    'review': file.read(),\n",
    "                    'film_id': urls[index][28:35],\n",
    "                    'target': target\n",
    "                })\n",
    "    \n",
    "        with open('data/imdb/%s.json' % sample, 'w') as file:\n",
    "            json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3697a336d8f441c1839e04f991938471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='sample', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for sample in tqdm_notebook(['train', 'test'], desc='sample'):\n",
    "    if not os.path.exists('data/imdb/%s.json' % sample):\n",
    "        sample2json(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чудно, займемся делом. Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, precision_score, recall_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pipelinehelper import PipelineHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А также чудесные jsonы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = json.load(open('data/imdb/train.json'))\n",
    "test = json.load(open('data/imdb/test.json'))\n",
    "X_train = [item['review'] for item in train]\n",
    "y_train = [int(item['target'] == 'pos') for item in train]\n",
    "X_test = [item['review'] for item in test]\n",
    "y_test = [int(item['target'] == 'pos') for item in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим [baseline](http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html). Однако для этого используем в некоем смысле универсальный Pipeline, используя на последнем шаге три разных классификатора при помощи [pipelinehelper](https://github.com/bmurauer/pipelinehelper). ~~также см [класс](http://www.davidsbatista.net/blog/2018/02/23/model_optimization/)~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', PipelineHelper([\n",
    "        ('bayes', MultinomialNB()),\n",
    "        ('sgd', SGDClassifier(max_iter=1000, tol=1e-3)),\n",
    "        ('svc', LinearSVC())\n",
    "    ]))\n",
    "])\n",
    "    \n",
    "param_grid = {\n",
    "    'clf__selected_model': text_clf.named_steps['clf'].generate({})\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:   16.5s remaining:   57.9s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   9 | elapsed:   17.2s remaining:   34.5s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:   17.4s remaining:   21.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   9 | elapsed:   17.4s remaining:   13.9s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:   21.4s remaining:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   9 | elapsed:   21.6s remaining:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   24.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   24.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__selected_model': ('sgd', {})}\n",
      "0.9577251329900329\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(text_clf, param_grid, scoring='roc_auc', cv=3, verbose=10, n_jobs=-1, return_train_score=True)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем кастомный токенайзер на основе work_tokenize + WordNetLemmatizer, LancasterStemmer, SnowballStemmer, PorterStemmer. В отдельный файл пришлось выделить из-за ошибок в GridSearch, мол не могу запиклить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local_utils import LemmaTokenizer, StemTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', PipelineHelper([\n",
    "        ('bayes', MultinomialNB()),\n",
    "        ('sgd', SGDClassifier(max_iter=1000, tol=1e-3)),\n",
    "        ('svc', LinearSVC(dual=True))\n",
    "    ]))\n",
    "])\n",
    "    \n",
    "tfidf_param_grid = {\n",
    "    'clf__selected_model': text_clf.named_steps['clf'].generate({}),\n",
    "    'vect__tokenizer': [None,\n",
    "                        LemmaTokenizer(),\n",
    "                        StemTokenizer('lancaster')], # еще 'snowball', 'porter'\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)], # еще (1, 3), но я умру пока это досчитается\n",
    "    'tfidf__smooth_idf': [True, False],\n",
    "    'tfidf__sublinear_tf': [False, True]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уберем TfidfTransformer и получим Bag of Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', PipelineHelper([\n",
    "        ('bayes', MultinomialNB()),\n",
    "        ('sgd', SGDClassifier(max_iter=1000, tol=1e-3)),\n",
    "        ('svc', LinearSVC(dual=True))\n",
    "    ]))\n",
    "])\n",
    "    \n",
    "bow_param_grid = {\n",
    "    'clf__selected_model': text_clf.named_steps['clf'].generate({}),\n",
    "    'vect__tokenizer': [None,\n",
    "                        LemmaTokenizer(),\n",
    "                        StemTokenizer('lancaster')], # еще 'snowball', 'porter'\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (1, 3)]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем эти махины на небольшой подвыборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = list(zip(X_train, y_train))\n",
    "X_train_subsample, y_train_subsample = zip(*np.concatenate([\n",
    "    np.random.permutation(temp[:12500])[:250], # pos\n",
    "    np.random.permutation(temp[12500:])[:250]  # neg\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    0.3s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   9 | elapsed:    0.4s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:    0.4s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   9 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    0.4s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   9 | elapsed:    0.5s remaining:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__selected_model': ('bayes', {})}\n",
      "0.8625200803212851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "bow_grid = GridSearchCV(bow_clf, param_grid, scoring='roc_auc', cv=3, verbose=10, n_jobs=-1, return_train_score=True)\n",
    "bow_grid.fit(X_train_subsample, y_train_subsample)\n",
    "\n",
    "print(bow_grid.best_params_)\n",
    "print(bow_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 180 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   38.5s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   49.0s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 297 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 405 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 465 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed:  7.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__selected_model': ('bayes', {}), 'tfidf__smooth_idf': True, 'tfidf__sublinear_tf': True, 'vect__ngram_range': (1, 1), 'vect__tokenizer': <local_utils.StemTokenizer object at 0x7f67430a3390>}\n",
      "0.905877223178428\n"
     ]
    }
   ],
   "source": [
    "tfidf_grid = GridSearchCV(tfidf_text_clf, param_grid, scoring='roc_auc', cv=3, verbose=10, n_jobs=-1, return_train_score=True)\n",
    "tfidf_grid.fit(X_train_subsample, y_train_subsample)\n",
    "\n",
    "print(tfidf_grid.best_params_)\n",
    "print(tfidf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция строит ROC, считает AUC, precision и recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred_proba):\n",
    "#     y_pred = [int(item[0] <= item[1]) for item in y_pred_proba]\n",
    "#     print(classification_report(y_true, y_pred))\n",
    "\n",
    "#     precision = precision_score(y_true, y_pred)\n",
    "#     recall = recall_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
    "    curve_roc = np.array([fpr, tpr])\n",
    "    plt.plot(fpr, tpr, label='ROC curve: AUC=%0.3f' % auc, color='darkorange', lw=1)\n",
    "#     plt.title('precision: %0.3f, recall: %0.3f' % (precision, recall))\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.ylim([0.0, 1.02])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "#     return auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = grid.best_estimator_.predict_proba(X_test)\n",
    "proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(y_test, proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
